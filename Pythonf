import io
from PIL import Image, ImageEnhance, ImageFilter

def preprocess_image_for_ocr(image_path: str, output_path: str = None) -> bytes:
    """
    Applies advanced image pre-processing steps for better OCR,
    especially for Kanji characters, using Pillow.

    Args:
        image_path: Path to the input image file.
        output_path: Optional path to save the preprocessed image.
                     If None, the processed image bytes are returned directly.

    Returns:
        Bytes of the preprocessed image.
    """
    try:
        with Image.open(image_path) as img:
            # 1. Convert to Grayscale
            # Grayscale simplifies the image, removing color noise and focusing on luminance.
            img_processed = img.convert("L") # 'L' mode for grayscale

            # 2. Enhance Contrast
            # Increases the difference between text and background, making characters stand out.
            # Factor > 1.0 increases contrast. Experiment with values like 1.5 to 2.5.
            enhancer = ImageEnhance.Contrast(img_processed)
            img_processed = enhancer.enhance(2.0) # Experiment with this factor

            # 3. Enhance Sharpness
            # Sharpens edges of characters, which can be crucial for intricate Kanji.
            # Factor > 1.0 increases sharpness. Experiment with values like 1.5 to 2.0.
            enhancer = ImageEnhance.Sharpness(img_processed)
            img_processed = enhancer.enhance(1.8) # Experiment with this factor

            # 4. Apply Binarization (Thresholding)
            # Converts image to pure black and white. This is often very effective for OCR
            # as it removes shades of gray, making characters binary (on or off).
            # The threshold value (e.g., 180) determines the cutoff point.
            # Pixels below threshold become black, above become white.
            # This is critical and often needs fine-tuning based on your image set.
            # You might need to dynamically determine the threshold or try a few values.
            threshold = 180 # Example threshold, adjust based on your image lighting
            img_processed = img_processed.point(lambda p: p > threshold and 255)

            # 5. Denoising (Optional)
            # Small specks or noise can confuse OCR. Median filter can help.
            # Kernel size (e.g., 3) determines the area for noise reduction.
            # img_processed = img_processed.filter(ImageFilter.MedianFilter(size=3))

            # 6. Resizing (Optional, but important if resolution is too low/high)
            # If the original image is too small, upscaling can help, but don't overdo it.
            # If the image is extremely large, downscaling can speed up processing and
            # prevent issues with some OCR APIs.
            # target_dpi = 300 # A common target for OCR
            # current_dpi = img.info.get('dpi', (72, 72))[0] # Get original DPI if available
            # if current_dpi < target_dpi:
            #     scale_factor = target_dpi / current_dpi
            #     new_size = (int(img_processed.width * scale_factor), int(img_processed.height * scale_factor))
            #     img_processed = img_processed.resize(new_size, Image.LANCZOS) # LANCZOS for good quality
            # elif current_dpi > target_dpi and img_processed.width > 2000: # Example max width
            #     scale_factor = target_dpi / current_dpi
            #     new_size = (int(img_processed.width * scale_factor), int(img_processed.height * scale_factor))
            #     img_processed = img_processed.resize(new_size, Image.LANCZOS)


            # Save to an in-memory bytes buffer
            img_byte_arr = io.BytesIO()
            # For binarized images, PNG is often a good choice as it's lossless and handles B&W well.
            img_processed.save(img_byte_arr, format="PNG")
            img_bytes = img_byte_arr.getvalue()

            if output_path:
                with open(output_path, 'wb') as f:
                    f.write(img_bytes)
                print(f"Preprocessed image saved to: {output_path}")

            return img_bytes

    except FileNotFoundError:
        print(f"Error: Image file not found at {image_path}")
        return None
    except Exception as e:
        print(f"Error during image preprocessing: {e}")
        return None

# Example Usage (you can integrate this into your main OCR script)
if __name__ == "__main__":
    # Create a dummy image for testing if you don't have one
    dummy_image_path = "kanji_input_original.png"
    if not os.path.exists(dummy_image_path):
        print(f"Creating a dummy image '{dummy_image_path}' for demonstration.")
        from PIL import ImageDraw, ImageFont
        img_size = (600, 200)
        img = Image.new('RGB', img_size, color = (255, 255, 255))
        d = ImageDraw.Draw(img)
        try:
            font_path = "C:/Windows/Fonts/msgothic.ttc" # Common Windows path
            if not os.path.exists(font_path):
                font_path = "/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc" # Common macOS path
                if not os.path.exists(font_path):
                    print("Warning: Common Kanji font not found. Using default font, Kanji might not render correctly.")
                    font = ImageFont.load_default()
                else:
                    font = ImageFont.truetype(font_path, 40)
            else:
                font = ImageFont.truetype(font_path, 40)
        except Exception as font_err:
            print(f"Could not load Kanji font: {font_err}. Using default font which may not display Kanji.")
            font = ImageFont.load_default()

        text1 = "日本語" # Japanese for "Japanese language"
        text2 = "漢字"   # Japanese for "Kanji characters"
        text3 = "読み取り" # Japanese for "reading/read"

        d.text((50, 30), text1, fill=(0, 0, 0), font=font)
        d.text((50, 90), text2, fill=(0, 0, 0), font=font)
        d.text((50, 150), text3, fill=(0, 0, 0), font=font)

        img.save(dummy_image_path)
        print(f"Dummy image '{dummy_image_path}' created successfully.")

    # Apply preprocessing
    preprocessed_image_bytes = preprocess_image_for_ocr(dummy_image_path, "kanji_output_preprocessed.png")

    if preprocessed_image_bytes:
        print("Image preprocessing successful. Check 'kanji_output_preprocessed.png' for the result.")
        # Now you would send `preprocessed_image_bytes` to your Azure OCR API
    else:
        print("Image preprocessing failed.")
